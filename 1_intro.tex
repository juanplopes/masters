%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\chapter{Introdução}
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

O rápido aumento da capacidade computacional nas últimas décadas impulsionou a criação de novos sistemas que consomem imensos volumes de dados em um fluxo contínuo. Exemplos destes sistemas incluem aplicações financeiras, sistemas de telemetria de equipamentos e servidores, redes de sensores em plantas de produção, navios ou plataformas de petróleo, análise de transações em aplicações web, dentre muitas outras..

Nestes sistemas, muitas vezes não é viável carregar todos os dados em um SGBD relacional para posteriormente efetuar as consultas necessárias. Normalmente a latência obtida nesta abordagem não é suficiente para o tipo de respostas que se deseja obter. As consultas precisam ser executadas continuamente sobre os dados que chegam. Historicamente, os SGBDs não permitem a execução de este tipo de consultas \cite{terry1992continuous}. Consultas contínuas diferem de consultas tradicionais por manterem um certo estado em memória e emitirem potencialmente mais de um resultado, sempre que alguma condição para tal for atingida. Alguns exemplos de tipos de consultas incluem:

\begin{itemize}
  \item \textbf{consultas periódicas:} os resultados da consulta devem ser atualizados após a passagem de um certo período de tempo;
  \item \textbf{consultas de transformação:} os resultados da consulta devem ser atualizados sempre que um novo registro é adicionado ao sistema;
  \item \textbf{consultas de eventos complexos:} os resultados da consulta devem ser atualizados sempre que um padrão complexo é detectado, por exemplo: o recebimento de dois registros seguidos com menos de 10 segundos de diferença entre eles.
\end{itemize}

Neste contexto, surge a necessidade de um novo modelo de processamento de dados, onde as consultas operam apenas sobre novos registros recebidos pelo sistema. Esses registros geralmente são imutáveis, porém fazem parte de fluxos de dados potencialmente infinitos. Outros desafios envolvem a imprevisibilidade sobre a ordem ou taxa de chegada desses registros, bem como a inviabilidade de analisar a qualquer momento os registros recebidos anteriormente. Algoritmos que funcionam em um modelo de fluxo de dados geralmente precisam ser capazes de computar resultados com apenas uma passagem sobre os dados \cite{babcock2002models}.

Como os fluxos de dados podem ser virtualmente infinitos, a quantidade de memória necessária para consultas arbitrárias sobre eles também tende a crescer indefinidamente. Embora algoritmos que executam eficientemente fora da memória principal venham sendo estudados ao longo das últimas décadas, estes algoritmos não se mostram apropriados para uso em aplicações em tempo real, por geralmente não suportarem consultas contínuas e por terem desempenho aquém do requerido para aplicações com alto volume de eventos. Por este motivo, focaremos em algoritmos que usam apenas uma quantidade finita da memória principal para efetuar suas operações \cite{alon1996space}.

Alguns problemas podem ter algoritmos trivialmente adaptados para funcionar neste modelo de processamento, como o cálculo da média. Outros, entretanto, podem não ser tão adequados. Um exemplo é o problema de calcular a mediana (ou qualquer quantil) em um fluxo de números inteiros, pois o mesmo requer mais de uma passagem pelos dados ou que eles sejam armazenados para computar o resultado. Em \cite{munro1980selection} mostra-se que calcular quantis em uma série com N valores em $p$ passagens pelos dados requer $\Omega(N^{\frac{1}{p}})$ espaço.

Neste trabalho, abordaremos estruturas de dados conhecidas como estruturas de sinopse (\emph{synopsis}) ou esboço (\emph{sketch}) \cite{gibbons1999synopsis}. Neste trabalho iremos nos referir a elas apenas como estruturas de dados probabilísticas. A principal característica destas é utilizar uma quantidade limitada de recursos. Em especial:

\begin{itemize}
  \item podem residir na memória principal, evitando operações de E/S;
  \item permitem atualização incremental;
  \item consomem menos recursos que os dados originais consumiriam, se fossem armazenados;
  \item podem ser facilmente transmitidas ou armazenadas;
  \item servem como substitutos de baixo custo dos dados originais, viabilizando alguns tipos de consultas.
\end{itemize}

Frequentemente, estruturas de dados probabilísticas descartam informações demais para representar fielmente os dados originais e permitir uma resposta exata às consultas. Estas estruturas de dados aproximam a resposta com um fator de erro relativo à quantidade de recursos destinados ao processamento.

Em especial, este trabalho foca nas estruturas que se aproveitam da codificação em \emph{hash} dos elementos de um conjunto ou multiconjunto para responder consultas específicas.

O trabalho está organizado da seguinte maneira: no Capítulo~\ref{cap:concepts}, introduziremos os conceitos básicos de probabilidade e funções \emph{hash} necessários para compreender as estruturas que serão apresentadas nas seções seguintes.

Ao longo do Capítulo~\ref{cap:probds} abordamos quatro estruturas probabilísticas. A característica comum entre elas é o uso de funções \emph{hash} para representar probabilisticamente certos conjuntos. Cada estrutura permite um certo conjunto de operações.

\begin{itemize}
  \item Na Seção~\ref{sec:bloom}, abordamos o filtro de Bloom \cite{bloom1970space}, uma estrutura de dados que responde consultas aproximadas de pertinência de elementos em um conjunto utilizando menos memória do que o necessário para armazenar o conjunto inteiro. É característica dos filtros de Bloom que as respostas negativas sejam exatas, enquanto as respostas positivas sejam aproximadas.
  
  \item Na Seção~\ref{sec:countmin}, consideramos a estrutura probabilística \emph{Count-Min} \cite{cormode2005improved}, que é análoga aos filtros de Bloom, permitindo estimar não só a pertinência, mas também a frequência de um elemento em um multiconjunto. Analogamente, qualquer frequência estimada pela estrutura é garantidamente maior ou igual à frequência real do elemento no multiconjunto. É também possível empregá-la para estimar quantis em um fluxo de dados.
  
  \item Na Seção~\ref{sec:minhash} introduzimos o \emph{MinHash} \cite{broder1997resemblance}, estrutura que permite estimar a semelhança entre dois conjuntos sem precisar compará-los elemento a elemento.
  
  \item Na Seção~\ref{sec:hyperloglog}, abordamos a estrutura \emph{HyperLoglog} \cite{flajolet2008hyperloglog}, que responde a cardinalidade aproximada de elementos distintos de um fluxo de dados utilizando memória adicional constante.
\end{itemize}

No Capítulo~\ref{cap:graphs} introduzimos a teoria sobre representações implícitas de grafos e apresentamos aplicações e ideias para representações implícitas probabilísticas baseadas em algumas estruturas apresentadas neste trabalho.

Concluímos no Capítulo~\ref{cap:conclusion}, resumindo as contribuições deste trabalho e sugerindo novos trabalhos futuros envolvendo representações de grafos utilizando estruturas de dados probabilísticas.


